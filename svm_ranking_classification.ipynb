{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon reviews Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.sparse import vstack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "amazon_review_dir = \"../amazon_reviews/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data source](http://jmcauley.ucsd.edu/data/amazon/)\n",
    "\n",
    "I download the 5-core review sets for the following product types: \"Video Games\", \"Beauty\", \"Cell Phones and Accessories\", and \"Musical Instruments\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amazon_reviews_no_dups(corpus_path,test_size=2000,seed=42):\n",
    "    '''loads a gzipped amazon review corpus, sampling a test set of 2000 reviews, with the rest becoming\n",
    "    training provided that they are not reviews of the same product or written by the same reviewers\n",
    "    as training data'''\n",
    "    g = gzip.open(corpus_path, 'r')\n",
    "    all_reviews = [eval(line) for line in g]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_reviews)\n",
    "    test_set = random.sample(all_reviews, test_size)\n",
    "    \n",
    "    test_reviewer = set([review[\"reviewerID\"] for review in test_set])\n",
    "    test_product = set([review[\"asin\"] for review in test_set])\n",
    "    \n",
    "    train_set = [review for review in all_reviews if review[\"reviewerID\"] not in test_reviewer and review[\"asin\"] not in test_product]\n",
    "    \n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SVM Regression as baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_vectorizer_regression(reviews):\n",
    "    '''\n",
    "    convert the reviews format into a list of texts and the overall rating\n",
    "    '''\n",
    "    \n",
    "    texts = []\n",
    "    classes = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        rating = review[\"overall\"]\n",
    "        classes.append(rating) \n",
    "        texts.append(review[\"summary\"] + \" \" + review[\"reviewText\"])\n",
    "        \n",
    "    return texts, classes\n",
    "\n",
    "def prepare_for_regression(train,test,max_n=2):\n",
    "    '''convert lists of reviews train and test to spare feature matrices X_train and X_test,\n",
    "    and lists of binary polarity classifications train_class and test_class'''\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,max_n),min_df=2)\n",
    "    train_texts, train_class = prepare_for_vectorizer_regression(train)\n",
    "    test_texts, test_class = prepare_for_vectorizer_regression(test)\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    return X_train,train_class, X_test,test_class\n",
    "\n",
    "\n",
    "def calculate_kdtau(path, max_n = 2):\n",
    "    '''\n",
    "    return the Kendall's Tau for the corresponding dataset at the specified path\n",
    "    '''\n",
    "    train_set, test_set = load_amazon_reviews_no_dups(amazon_review_dir + path)\n",
    "    train, train_class, test, test_class = prepare_for_regression(train_set,test_set, max_n = max_n)\n",
    "    svr = LinearSVR()\n",
    "    svr.fit(train, train_class)\n",
    "    \n",
    "    return kendalltau(test_class, svr.predict(test)), train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Video games\n",
      "Kendall's Tau: KendalltauResult(correlation=0.40585498119116903, pvalue=1.510440335427315e-126)\n",
      "trainshape: (126333, 1128763)\n",
      "-----\n",
      "For Beauty\n",
      "Kendall's Tau: KendalltauResult(correlation=0.4434249962697953, pvalue=2.3135221071252014e-148)\n",
      "trainshape: (118829, 496856)\n",
      "-----\n",
      "For Cellphones and accessories\n",
      "Kendall's Tau: KendalltauResult(correlation=0.44195392960366864, pvalue=3.805334351230243e-149)\n",
      "trainshape: (110419, 495892)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "regression_results = dict()\n",
    "\n",
    "for name, path in zip(names, paths):\n",
    "    print(\"For\", name)\n",
    "    kdtau, trainshape = calculate_kdtau(path)\n",
    "    regression_results[name] = (kdtau, trainshape)\n",
    "    print(\"Kendall's Tau:\", kdtau)\n",
    "    print(\"trainshape:\", trainshape)\n",
    "    print(\"-----\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SVM Ranking method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pairwise(data,ratings):\n",
    "    '''covert a normal collection of data with ordinal ratings into a pairwise classification task\n",
    "    by randomly choosing one comparison datapoint with a different rating and taking the direction of\n",
    "    the difference as the class of the new datapoint'''\n",
    "\n",
    "    new_feature_vector = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        current_rating = ratings[i]\n",
    "        diff_rating = current_rating\n",
    "        diff_ind = 0\n",
    "        \n",
    "        while diff_rating == current_rating:\n",
    "            \n",
    "            j = random.choice(range(data.shape[0]))\n",
    "            diff_rating = ratings[j]\n",
    "            diff_ind = j\n",
    "        \n",
    "        diff_feature_vector = data[i, :] - data[diff_ind, :]\n",
    "        new_feature_vector.append(diff_feature_vector)\n",
    "        \n",
    "        if current_rating > diff_rating:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    print('end iteration')      \n",
    "    new_matrix = vstack(new_feature_vector)\n",
    "    return new_matrix, labels\n",
    "            \n",
    "        \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kdtau_pairwise(path, max_n = 2):\n",
    "    '''\n",
    "    return the Kendall's Tau for the corresponding dataset at the specified path\n",
    "    '''\n",
    "    train_set, test_set = load_amazon_reviews_no_dups(amazon_review_dir + path)\n",
    "    train, train_class, test, test_class = prepare_for_regression(train_set,test_set, max_n = max_n)\n",
    "    pairwise_data, pairwise_class = convert_to_pairwise(train,train_class)\n",
    "    svr = LinearSVC()\n",
    "    svr.fit(pairwise_data, pairwise_class)\n",
    "    scores = test @ svr.coef_.T\n",
    "    \n",
    "    return kendalltau(test_class, scores), train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Video games\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "end iteration\n",
      "Kendall's Tau: KendalltauResult(correlation=0.49280871188427516, pvalue=1.2787581938933162e-185)\n",
      "trainshape: (126333, 1128763)\n",
      "-----\n",
      "For Beauty\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "end iteration\n",
      "Kendall's Tau: KendalltauResult(correlation=0.5404327850813158, pvalue=2.241975583784509e-219)\n",
      "trainshape: (118829, 496856)\n",
      "-----\n",
      "For Cellphones and accessories\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "end iteration\n",
      "Kendall's Tau: KendalltauResult(correlation=0.5501302804219165, pvalue=5.866806050815261e-230)\n",
      "trainshape: (110419, 495892)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "pairwise_results = dict()\n",
    "\n",
    "for name, path in zip(names, paths):\n",
    "    print(\"For\", name)\n",
    "    kdtau, trainshape = calculate_kdtau_pairwise(path)\n",
    "    pairwise_results[name] = (kdtau, trainshape)\n",
    "    print(\"Kendall's Tau:\", kdtau)\n",
    "    print(\"trainshape:\", trainshape)\n",
    "    print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
